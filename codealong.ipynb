{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac59c064-8f5c-4c09-a23d-a346ef51c980",
   "metadata": {},
   "source": [
    "# Data Visualization: Week 2, Lecture 1\n",
    "\n",
    "#### Learning Objectives\n",
    "By the end of this CodeAlong, students will be able to:\n",
    "- Perform and interpret the results of the augmented Dickey-Fuller test\n",
    "- Identify the necessary order of differencing to achieve stationarity\n",
    "- Plot ACF and PACF plots\n",
    "- Fit and evaluate an ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f9a2e-0c89-4018-84c2-5a91ab00aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn import set_config\n",
    "\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "\n",
    "import statsmodels.tsa.api as tsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f10ff-6171-489b-b4b1-a05166fb8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_config(transform_output=\"pandas\")\n",
    "# plt.rcParams[\"figure.figsize\"] = (12, 4)\n",
    "# sns.set_context(\"talk\", font_scale=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2766a047-85f0-4437-9ff1-b4f68de3035a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Custom functions\n",
    "\n",
    "These functions are imported from the LP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6bac5-746a-444c-9fe7-de78ccbcd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics(y_true, y_pred, label='', verbose = True, output_dict=False):\n",
    "  # Get metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False) \n",
    "    r_squared = r2_score(y_true, y_pred)\n",
    "    if verbose == True:\n",
    "        # Print Result with Label and Header\n",
    "        header = \"-\"*60\n",
    "        print(header, f\"Regression Metrics: {label}\", header, sep='\\n')\n",
    "        print(f\"- MAE = {mae:,.3f}\")\n",
    "        print(f\"- MSE = {mse:,.3f}\")\n",
    "        print(f\"- RMSE = {rmse:,.3f}\")\n",
    "        print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "    if output_dict == True:\n",
    "        metrics = {'Label':label, 'MAE':mae,\n",
    "                 'MSE':mse, 'RMSE':rmse, 'R^2':r_squared}\n",
    "        return metrics\n",
    "\n",
    "def evaluate_regression(reg, X_train, y_train, X_test, y_test, verbose = True,\n",
    "                        output_frame=False):\n",
    "    # Get predictions for training data\n",
    "    y_train_pred = reg.predict(X_train)\n",
    "\n",
    "    # Call the helper function to obtain regression metrics for training data\n",
    "    results_train = regression_metrics(y_train, y_train_pred, verbose = verbose,\n",
    "                                     output_dict=output_frame,\n",
    "                                     label='Training Data')\n",
    "    print()\n",
    "    # Get predictions for test data\n",
    "    y_test_pred = reg.predict(X_test)\n",
    "    # Call the helper function to obtain regression metrics for test data\n",
    "    results_test = regression_metrics(y_test, y_test_pred, verbose = verbose,\n",
    "                                  output_dict=output_frame,\n",
    "                                    label='Test Data' )\n",
    "\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    if output_frame:\n",
    "        results_df = pd.DataFrame([results_train,results_test])\n",
    "        # Set the label as the index \n",
    "        results_df = results_df.set_index('Label')\n",
    "        # Set index.name to none to get a cleaner looking result\n",
    "        results_df.index.name=None\n",
    "        # Return the dataframe\n",
    "        return results_df.round(3)\n",
    "    \n",
    "# Custom function for Ad Fuller Test\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91fa47-db0a-4a52-af54-53937a79a6bc",
   "metadata": {},
   "source": [
    "## Importing data & exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd87e8d-e8ae-40d6-bf89-f8a53403e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunscreen\n",
    "df = pd.read_csv('sunscreen_popularity.txt', skiprows= [0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122006c1-9858-4bda-be6f-c04c1fcaea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "ax = df.plot()\n",
    "ax.set(ylabel=\"Popularity\", xlabel=\"Time\", title=\"Google Trends popularity for sunscreen\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee60cc-9ffa-4537-bb3f-caa6a8d4a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886475c2-4623-4ec7-8883-ab81ea94986d",
   "metadata": {},
   "source": [
    "#### Set month to index, set frequency, and check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756575fd-e881-49d8-84f2-28edd3abb697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast month as date time, set index, set freq, check nulls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022066b-fe5d-4991-9174-e90739ab6877",
   "metadata": {},
   "source": [
    "#### Train-test split with test_size=0.05, check dimensions, and plot train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf6113-58ee-4b97-8cba-26d43b666847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47aa76f-d711-4581-a802-972fd8fce4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a36919-d283-47b0-80a0-c56e28a6baaa",
   "metadata": {},
   "source": [
    "## Testing for stationarity\n",
    "\n",
    "Recall that we use the augmented Dickey-Fuller test to evaluate whether our data are stationary.\n",
    "\n",
    "If the p-value is less than alpha, we reject the null hypothesis of non-stationarity. Otherwise we fail to reject.\n",
    "\n",
    "### Use the ADF to evaluate for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7193d5-cbf7-4638-9bfd-d549b8639059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_adfuller_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c16c03-6234-4166-b34e-4795ce36d92b",
   "metadata": {},
   "source": [
    "### Use the ADF to evaluate whether once-differenced data are stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621d840-cd09-4247-a35a-abf827ce73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_adfuller_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037763b-dca4-4995-a56c-ea439b3fd0e0",
   "metadata": {},
   "source": [
    "### Use `ndiffs` to check order for making data stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717bd056-2e0d-419a-b929-d6fdd3af199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ndiffs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b213baf-c43d-48d4-9678-01a971798657",
   "metadata": {},
   "source": [
    "### Plot the differenced data as well as ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a38b29-4600-4baf-809f-c97add0fc05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot differenced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cc5ee-2f2b-4f55-a133-6ebffc3fe12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ACF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044afab1-06f4-4de5-a8d2-53634cb5b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PACF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463a98e-d871-4cf6-bb4c-1fba774704e1",
   "metadata": {},
   "source": [
    "## Fitting an ARIMA model\n",
    "\n",
    "Remember that identifying the orders of an ARIMA model can be challenging when both p and q are non-zero.\n",
    "\n",
    "There are also seasonal trends in this dataset. Our linear ARIMA model may not capture those patterns well!\n",
    "\n",
    "Let's start with a model of order (2,1,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d3877-3745-445d-b64f-2476f3112777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the orders (p,d,q)\n",
    "p = \n",
    "d = \n",
    "q = \n",
    "\n",
    "# Now instantiate the model with the data and fit\n",
    "model = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9823aba-058c-4c40-9471-7c8757321685",
   "metadata": {},
   "source": [
    "## Evaluating the ARIMA model\n",
    "\n",
    "Check the model summary.\n",
    "\n",
    "Store the model forecast using `model.get_forecast()` as `preds_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bc566-d49b-4c28-bf03-06e900980549",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632991c-bcef-49f7-b7d8-963bd590ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model.get_forecast()\n",
    "# what does summary_frame() do? why might this be useful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f586a2c-1dad-41fc-9ba4-8a8c255c5af2",
   "metadata": {},
   "source": [
    "## Check forecast by plotting and calculating evaluation metrics\n",
    "\n",
    "### Additional custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b4e26-4a48-4478-b338-88ad24b24f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(ts_train, ts_test, forecast_df, n_train_lags=None, \n",
    "                  figsize=(10,4), title='Comparing Forecast vs. True Data'):\n",
    "    ### PLot training data, and forecast (with upper/,lower ci)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # setting the number of train lags to plot if not specified\n",
    "    if n_train_lags==None:\n",
    "        n_train_lags = len(ts_train)\n",
    "            \n",
    "    # Plotting Training  and test data\n",
    "    ts_train.iloc[-n_train_lags:].plot(ax=ax, label=\"train\")\n",
    "    ts_test.plot(label=\"test\", ax=ax)\n",
    "    # Plot forecast\n",
    "    forecast_df['mean'].plot(ax=ax, color='green', label=\"forecast\")\n",
    "    # Add the shaded confidence interval\n",
    "    ax.fill_between(forecast_df.index, \n",
    "                    forecast_df['mean_ci_lower'],\n",
    "                   forecast_df['mean_ci_upper'],\n",
    "                   color='green', alpha=0.3,  lw=2)\n",
    "    # set the title and add legend\n",
    "    ax.set_title(title)\n",
    "    ax.legend();\n",
    "    \n",
    "    return fig, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b04dd-f7a0-4ea2-9675-635839912edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def regression_metrics_ts(ts_true, ts_pred, label=\"\", verbose=True, output_dict=False,):\n",
    "    # Get metrics\n",
    "    mae = mean_absolute_error(ts_true, ts_pred)\n",
    "    mse = mean_squared_error(ts_true, ts_pred)\n",
    "    rmse = mean_squared_error(ts_true, ts_pred, squared=False)\n",
    "    r_squared = r2_score(ts_true, ts_pred)\n",
    "    mae_perc = mean_absolute_percentage_error(ts_true, ts_pred) * 100\n",
    "\n",
    "    if verbose == True:\n",
    "        # Print Result with label\n",
    "        header = \"---\" * 20\n",
    "        print(header, f\"Regression Metrics: {label}\", header, sep=\"\\n\")\n",
    "        print(f\"- MAE = {mae:,.3f}\")\n",
    "        print(f\"- MSE = {mse:,.3f}\")\n",
    "        print(f\"- RMSE = {rmse:,.3f}\")\n",
    "        print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "        print(f\"- MAPE = {mae_perc:,.2f}%\")\n",
    "\n",
    "    if output_dict == True:\n",
    "        metrics = {\n",
    "            \"Label\": label,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MAPE(%)\": mae_perc,\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85883786-1efe-4327-844f-df204d59395a",
   "metadata": {},
   "source": [
    "### Use the custom functions to plot the forecast, display the evaluation metrics, and plot model diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720fb49-0c49-484d-ab20-6e4d92a51a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plot_forecast()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e0bd0a-c024-4709-9620-3d889e4b8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regression_metrics_ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4928d7-d0bc-43ac-9087-886ddaace689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model.plot_diagnostics()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
